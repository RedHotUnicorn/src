---
title: Seeing Theory - Basic Probability
date: 2021-08-23
src_link: https://www.notion.so/Seeing-Theory-Basic-Probability-5f9a2c1435794ba0aaf82f1cbaa354bd
src_date: '2021-08-23 13:27:00'
gold_link: https://seeing-theory.brown.edu/basic-probability/index.html
gold_link_hash: 93cf400f2caf5004b25d2d9625fa5da6
tags:
- '#host_seeing-theory_brown_edu'
---


#### Chapter 1


Basic Probability
=================


This chapter is an introduction to the basic concepts of probability theory.
 


![](../img/button/bottom-arrow.svg)

### Chance Events


Randomness is all around us. Probability theory is the mathematical framework that allows us to analyze chance events in a logically sound manner. The probability of an event is a number indicating how likely that event will occur. This number is always between 0 and 1, where 0 indicates impossibility and 1 indicates certainty.


A classic example of a probabilistic experiment is a fair coin toss, in which the two possible outcomes are heads or tails. In this case, the probability of flipping a head or a tail is 1/2. In an actual series of coin tosses, we may get more or less than exactly 50% heads. But as the number of flips increases, the long-run frequency of heads is bound to get closer and closer to 50%.


Flip the Coin
Flip 100 times
 For an unfair or weighted coin, the two outcomes are not equally likely. You can change the weight or distribution of the coin by dragging the true probability bars (on the right in blue) up or down. If we assign numbers to the outcomes â say, 1 for heads, 0 for tails â then we have created the mathematical object known as a [random variable](../probability-distributions/index.html#section1).




### Expectation


The expectation of a random variable is a number that attempts to capture the center of that random variable's distribution. It can be interpreted as the long-run average of many independent samples from the given distribution. More precisely, it is defined as the probability-weighted sum of all possible values in the random variable's support,


$$\text{E}[X] = \sum\_{x \in \mathcal{X}}xP(x)$$
Consider the probabilistic experiment of rolling a fair die and watch as the running sample mean converges to the expectation of 3.5.


Roll the Die
Roll 100 times
Change the distribution of the different faces of the die (thus making the die biased or "unfair") by adjusting the blue bars below and observe how this changes the expectation.




### Variance


Whereas expectation provides a measure of centrality, the variance of a random variable quantifies the spread of that random variable's distribution. The variance is the average value of the squared difference between the random variable and its expectation,


$$\text{Var}(X) = \text{E}[(X - \text{E}[X])^2]$$
Draw cards randomly from a deck of ten cards. As you continue drawing cards, observe that the running average of squared differences (in green) begins to resemble the true variance (in blue).


Draw a Card
Draw 100 times
Toggle which cards you want to include in the deck by clicking on them below.